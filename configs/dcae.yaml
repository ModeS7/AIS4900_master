# DC-AE (Deep Compression Autoencoder) Training Configuration
#
# High-compression 2D autoencoder for MRI slice encoding.
# Based on MIT HAN Lab's DC-AE: https://arxiv.org/abs/2410.10733
#
# Key features:
# - 32× or 64× spatial compression (vs 4-8× for standard VAE)
# - Residual autoencoding for stable high-compression training
# - Better reconstruction than SD-VAE-f8 at higher compression
#
# Training Phases (from paper):
# - Phase 1: L1 + Perceptual loss only (main training, no GAN)
# - Phase 3: GAN local refinement (freeze all EXCEPT decoder head layers)
#
# Usage:
#   # Phase 1: Train from scratch with f32 (default)
#   python -m medgen.scripts.train_dcae
#
#   # Phase 1: Fine-tune from pretrained ImageNet weights
#   python -m medgen.scripts.train_dcae dcae.pretrained="mit-han-lab/dc-ae-f32c32-in-1.0-diffusers"
#
#   # Phase 1: Use f64 compression
#   python -m medgen.scripts.train_dcae dcae=f64
#
#   # Phase 3: GAN refinement (freeze all EXCEPT decoder head ~1.4K params)
#   # Paper: "we only tune the head layers of the decoder"
#   python -m medgen.scripts.train_dcae \
#       training.phase=3 \
#       dcae.adv_weight=0.1 \
#       dcae.disc_lr=5.4e-5 \
#       training.learning_rate=5.4e-5 \
#       pretrained_checkpoint=runs/compression_2d/.../checkpoint_best.pt
#
#   # Cluster training
#   python -m medgen.scripts.train_dcae paths=cluster
#
#   # Segmentation mask compression (BCE + Dice + Boundary loss)
#   python -m medgen.scripts.train_dcae \
#       mode=seg_compression \
#       dcae.seg_mode=true

defaults:
  - paths: local
  - mode: multi_modality  # Single-channel slices from all modalities
  - dcae: f32  # Default to f32c32 (32× compression)
  - training: default
  - _self_

# Model settings (for dataloader compatibility)
model:
  image_size: 256

# Checkpoint for resuming training
pretrained_checkpoint: null

# ============================================================================
# Training Overrides for DC-AE
# ============================================================================
training:
  epochs: 100
  batch_size: 16  # 2D slices, can use larger batches
  learning_rate: 1.0e-4
  gradient_clip_norm: 1.0
  warmup_epochs: 5
  # Validates every epoch, figures logged at figure_interval=10
  use_ema: false
  use_compile: false  # torch.compile causes OOM with DC-AE's 362M params

  # Training phase (paper uses 3-phase approach)
  # Phase 1: L1 + Perceptual loss (main training, full model)
  # Phase 3: Add GAN loss (only decoder head trainable ~1.4K params)
  phase: 1

  # Logging (all enabled for consistent tracking)
  logging:
    grad_norm: true
    regional_losses: true     # Tumor/background tracking
    psnr: true
    lpips: true
    msssim: true
    flops: true

hydra:
  run:
    dir: ${paths.model_dir}/compression_2d/${mode.name}/${oc.select:training.name,""}${now:%Y%m%d-%H%M%S}
  sweep:
    dir: ${paths.model_dir}/compression_2d/multirun/${now:%Y%m%d-%H%M%S}
    subdir: ${hydra.job.num}
