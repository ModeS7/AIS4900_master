# Default Training Configuration
#
# Common training hyperparameters used across all training scripts.
# Override via CLI: python -m medgen.scripts.train training.epochs=1000

# Experiment name prefix for run directory
# Include trailing underscore: training.name=exp1_ -> exp1_rflow_128_...
name: ""

# Core training parameters
epochs: 500                # Total training epochs
batch_size: 16             # Batch size per GPU
limit_train_batches: null  # Limit batches per epoch (null = use all, int = limit)
learning_rate: 1.0e-4      # Base learning rate
gradient_clip_norm: 1.0    # Max gradient norm (prevents explosions)
warmup_epochs: 5           # Linear warmup epochs (0.1x -> 1x LR)
figure_interval: 20        # Log figures every N epochs
augment: false             # Data augmentation (disabled by default for diffusion)
augment_type: diffusion    # Augmentation type: "diffusion" (conservative) or "vae" (aggressive)

# Batch-level augmentations (VAE only - mixup/cutmix)
batch_augment:
  enabled: false           # Disabled by default, enabled in VAE configs
  mixup_prob: 0.0          # Probability of mixup per batch
  cutmix_prob: 0.0         # Probability of cutmix per batch

# Score Augmentation - applies transforms to noisy data (after noise addition)
# Reference: https://arxiv.org/abs/2508.07926
# Unlike traditional augmentation (which augments clean data), ScoreAug transforms
# the noisy input and target together, teaching equivariant denoising.
#
# Per paper: "one augmentation method is randomly selected with equal probability
# across all types" - identity is always included, so with 4 transforms enabled,
# each has 20% probability (1/5).
#
# Conditioning requirements:
# - rotation/flip: REQUIRES omega conditioning (noise distribution is invariant)
# - translation/cutout: Work without conditioning but risk data leakage
# - brightness: Linear transform, works without conditioning
score_aug:
  enabled: false             # Disabled by default
  # Transforms - each enabled transform has equal probability
  # Spatial transforms (D4 dihedral symmetries) - rotation and flip are combined:
  #   - rotation only: 3 options (90°, 180°, 270°)
  #   - flip only: 2 options (hflip, vflip)
  #   - both: 7 options (3 rot + 2 flip + 2 rot+flip combos)
  rotation: true             # 90, 180, 270 degree rotations (requires omega)
  flip: true                 # Horizontal + vertical flip (requires omega)
  translation: false         # +-40% X, +-20% Y translation with zero-pad
  cutout: false              # Random rectangle cutout (10-30% each dimension)
  brightness: false          # Brightness scaling (experimental with normalized data)
  brightness_range: 1.2      # Max scale factor B, samples in [1/B, B]
  use_omega_conditioning: true   # Always use omega conditioning when ScoreAug is enabled
  # Compose mode: apply transforms independently instead of picking one
  compose: false             # If true, each transform applied with compose_prob
  compose_prob: 0.5          # Probability for each transform in compose mode

  # Mode intensity scaling: multiply input by mode-specific scale factor
  # Forces model to use mode conditioning to predict correct target
  mode_intensity_scaling: false  # Requires use_omega_conditioning + mode.use_mode_embedding

  # === v2 mode: structured non-destructive/destructive augmentation ===
  # When enabled, separates transforms into:
  # - Non-destructive (can stack): rotation, flip, translation
  # - Destructive (pick one): cutout OR fixed patterns
  v2_mode: false             # Enable v2 structured augmentation
  nondestructive_prob: 0.5   # Probability for each non-destructive transform
  destructive_prob: 0.5      # Probability of applying any destructive transform
  cutout_vs_pattern: 0.5     # Split between cutout (random) and patterns (fixed)

  # Fixed pattern options (16 total patterns, 4 per category)
  # Patterns are deterministic masks learned via one-hot embedding
  patterns:
    checkerboard: true       # 4×4 and 8×8 alternating grids (IDs 0-3)
    grid_dropout: true       # Random 25%/50% grid cells dropped (IDs 4-7)
    coarse_dropout: true     # 2-4 large holes at corners/edges (IDs 8-11)
    patch_dropout: true      # MAE-style 25%/50% patches dropped (IDs 12-15)

# ============================================================================
# Shifted Data Augmentation (SDA)
# ============================================================================
# Reference: IEEE Access 2025 - "Regularization for Unconditional Image
# Diffusion Models via Shifted Data Augmentation"
#
# Key difference from ScoreAug:
# - ScoreAug: transforms NOISY data (after noise addition), requires omega
# - SDA: transforms CLEAN data (before noise addition), uses noise shift
#
# SDA uses dual-path training:
# 1. Standard path: x -> add_noise(t) -> denoise -> x
# 2. Augmented path: T(x) -> add_noise(t + delta) -> denoise -> T(x)
#
# The shifted noise level prevents leakage by giving augmented samples
# different SNR characteristics.
#
# Note: Do not use SDA and ScoreAug together (they do similar things differently)
sda:
  enabled: false             # Disabled by default
  rotation: true             # 90, 180, 270 degree rotations
  flip: true                 # Horizontal + vertical flip
  noise_shift: 0.1           # Amount to shift timesteps (0.05-0.2 typical)
  prob: 0.5                  # Probability of using augmented path
  weight: 1.0                # Weight for augmented path loss

# DataLoader optimization for CPU augmentation
dataloader:
  num_workers: 8           # Parallel data loading workers
  prefetch_factor: 4       # Batches to prefetch per worker
  pin_memory: true         # Faster CPU->GPU transfer
  persistent_workers: true # Avoid worker respawn overhead

# EMA (Exponential Moving Average)
# Maintains slowly-updated weight copy for higher quality samples
use_ema: false
ema:
  decay: 0.9999            # EMA decay rate (0.999-0.9999)
  update_after_step: 100   # Start EMA after this many steps
  update_every: 10         # Update EMA every N steps

# Min-SNR Loss Weighting (DDPM ONLY)
# Reweights per-sample loss by timestep to prevent high-noise step domination.
# Uses SNR = alpha_bar / (1 - alpha_bar) from DDPM's noise schedule.
# NOTE: Has no theoretical basis for RFlow - will be auto-disabled with warning.
# Reference: https://arxiv.org/abs/2303.09556
use_min_snr: false
min_snr_gamma: 5.0         # SNR clipping threshold

# SAM (Sharpness-Aware Minimization)
# Seeks flat minima for better generalization. Requires 2x compute per step.
# Reference: https://arxiv.org/abs/2010.01412
sam:
  enabled: false             # Enable SAM optimizer
  rho: 0.05                  # Perturbation radius (0.01-0.1 typical)
  adaptive: false            # Use ASAM (adaptive, weight-scale invariant)

# DC-AE 1.5: Augmented Diffusion Training
# Applies channel masking to latent diffusion training to accelerate convergence.
# MUST be used together with structured latent space autoencoder (dcae.structured_latent.enabled=true).
# Using one without the other can hurt results (per paper ablation).
#
# Reference: "DC-AE 1.5: Accelerating Diffusion Model Convergence with Structured Latent Space"
# https://arxiv.org/abs/2508.00413
#
# Algorithm (Eq. 2):
#   1. Sample random channel count c' from [min_channels, ..., latent_channels]
#   2. Create mask: [1,...,1 (c' times), 0,...,0]
#   3. Apply mask to noisy latent AND noise target
#   4. Compute loss only on masked channels
#
# Results: 6x faster convergence on UViT-H, DiT-XL gFID 26.44 -> 17.31
#
# Usage:
#   python -m medgen.scripts.train mode=bravo strategy=rflow \
#       vae_checkpoint=path/to/dcae_1_5.pt \
#       training.augmented_diffusion.enabled=true
augmented_diffusion:
  enabled: false             # Enable augmented diffusion training
  # Channel steps: [min_channels, min+step, ..., latent_channels]
  # Should match the structured latent space config used for autoencoder training
  min_channels: 16           # Minimum channels to keep (paper uses 16)
  channel_step: 4            # Step size between options (paper uses 4)
  # Only applies to latent diffusion (scale_factor > 1)
  # Has no effect on pixel-space diffusion

# Perceptual loss (SqueezeNet features)
# Disabled by default for diffusion - adds compute overhead with minimal benefit
perceptual_weight: 0.0     # Weight for perceptual loss term (0 = disabled)

# Multi-GPU (DDP)
use_multi_gpu: false
disable_ddp_optimizer: false  # Disable DDP optimizer for large models (saves memory)

# Learning rate scheduler
scheduler: cosine            # Options: "cosine" (default), "constant"
                             # cosine: warmup + cosine annealing to eta_min
                             # constant: warmup then constant LR (may help with overfitting)
eta_min: 1.0e-6              # Minimum LR for cosine annealing (only used if scheduler=cosine)

# Gradient Noise Injection
# Adds Gaussian noise to gradients for implicit regularization
# Reference: "Adding Gradient Noise Improves Learning" (Neelakantan et al., 2015)
# Noise decays as: sigma / (1 + step)^decay
gradient_noise:
  enabled: false             # Enable gradient noise injection
  sigma: 0.01                # Initial noise std (0.01-0.1 typical)
  decay: 0.55                # Noise decay exponent (paper uses 0.55)

# Curriculum Timestep Scheduling
# Progressively shifts from easy (low noise) to hard (high noise) timesteps
# Start training on easy samples, gradually introduce harder ones
curriculum:
  enabled: false             # Enable curriculum learning
  warmup_epochs: 50          # Epochs to reach full timestep range
  min_t_start: 0.0           # Initial minimum timestep (0.0 = start of range)
  max_t_start: 0.3           # Initial maximum timestep (0.3 = low noise only)
  min_t_end: 0.0             # Final minimum timestep
  max_t_end: 1.0             # Final maximum timestep (1.0 = full range)

# ============================================================================
# "Clean" Regularization Techniques
# ============================================================================
# These provide regularization benefits WITHOUT leaking augmentation patterns
# into generated samples (unlike standard data augmentation).

# Timestep Jitter - adds small noise to sampled timesteps
# Increases noise-level diversity without changing output distribution
timestep_jitter:
  enabled: false             # Enable timestep jitter
  std: 0.05                  # Std of Gaussian noise added to timesteps (in [0,1] range)

# Self-Conditioning via Consistency
# Runs model twice: first pass (no grad), second pass uses first prediction for consistency
# Adds consistency loss to encourage stable predictions
# This variant works without model architecture changes
self_conditioning:
  enabled: false             # Enable self-conditioning
  prob: 0.5                  # Probability of using self-conditioning per batch
  consistency_weight: 0.1    # Weight for consistency loss term

# Feature Perturbation - adds Gaussian noise to intermediate features
# Like continuous dropout, regularizes without augmentation leakage
feature_perturbation:
  enabled: false             # Enable feature perturbation
  std: 0.1                   # Std of noise added to features
  layers: ["mid"]            # Which layers to perturb: "encoder", "mid", "decoder", or list

# Input Noise Augmentation - perturbs the noise vector before adding to image
# Increases noise diversity without changing what model learns to output
noise_augmentation:
  enabled: false             # Enable noise augmentation
  std: 0.1                   # Std of perturbation added to noise vector

# Optimizer settings
optimizer:
  betas: [0.9, 0.999]        # AdamW momentum parameters (beta1, beta2)
                             # Default: [0.9, 0.999]
                             # Phase 3 GAN refinement: [0.5, 0.9] (per DC-AE paper)
  weight_decay: 0.0          # L2 regularization weight (default: 0.0)
                             # Typical values: 0.01, 0.05, 0.1

# torch.compile optimization
# Compiles model and loss functions for faster training
use_compile: true            # Compile VAE/discriminator/perceptual loss
compile_fused_forward: true  # Compile fused forward pass (diffusion only, ~10% speedup)
                             # Auto-disabled for latent space or Min-SNR

# Precision settings (VAE only)
# Pure BF16 training stores model weights in BF16 for memory savings
# Autocast continues to work as usual - this only affects weight storage
precision:
  dtype: bf16                # bf16, fp16, fp32 - model weight dtype when pure_weights=true
  pure_weights: false        # If true, model weights stored in low precision (saves ~50% memory)

# Logging and metrics (all logged every epoch, figures at figure_interval)
# Mode compatibility:
#   [seg] = segmentation only
#   [cond] = bravo/dual only
#   [all] = all modes
logging:
  # Training dynamics
  grad_norm: true              # [all] Track gradient norm (catches instability)
  timestep_losses: true        # [all] Loss by diffusion timestep
  regional_losses: true        # [cond] Loss by tumor vs background region
  timestep_region_losses: true # [cond] 2D heatmap: timestep x region

  # Validation metrics
  msssim: true                 # [cond] Multi-Scale Structural Similarity (2D/3D)
  psnr: true                   # [cond] Peak signal-to-noise ratio
  lpips: true                  # [cond] Learned Perceptual (2D only, slower)
  boundary_sharpness: true     # [cond] Edge quality in tumor regions

  # Visualization
  intermediate_steps: true     # [cond] Save denoising trajectory
  worst_batch: true            # [all] Save batch with highest loss each epoch
  num_intermediate_steps: 5    # How many steps to visualize

  # Performance
  flops: true                  # [all] Measure model FLOPs (once at start)

# PyTorch Profiler - exports Chrome traces for performance analysis
# View traces: Perfetto UI (https://ui.perfetto.dev) or chrome://tracing
# Reference: https://pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html
profiling:
  enabled: false              # Master switch
  wait: 5                     # Steps to skip (torch.compile warmup)
  warmup: 2                   # Steps to warm up profiler (discarded)
  active: 10                  # Steps to actively profile
  repeat: 1                   # Number of profiling cycles (0 = continuous)
  record_shapes: true         # Record tensor shapes
  profile_memory: true        # Track memory allocations
  with_stack: false           # Include Python call stacks (slower)
  with_flops: true            # Estimate FLOPs per operation

# Generation Quality Metrics (Diffusion only)
# Tracks KID, CMMD, FID to detect overfitting by comparing generated samples
# against train/val distributions. Uses ResNet50 for KID/FID, BiomedCLIP for CMMD.
# Reference features cached at training start for efficiency.
generation_metrics:
  enabled: true               # Enabled by default for overfitting detection
  samples_per_epoch: 100      # Samples for quick metrics (every epoch)
  samples_extended: 500       # Samples for extended metrics (every figure_interval)
  samples_test: 1000          # Samples for final test evaluation
  steps_per_epoch: 10         # Denoising steps for quick metrics
  steps_extended: 25          # Denoising steps for extended metrics
  steps_test: 50              # Denoising steps for test evaluation
  cache_dir: ".cache/generation_features"  # Feature cache location
  # feature_batch_size: null   # Defaults to training.batch_size for torch.compile consistency

# Region-Weighted Loss (Diffusion only - conditional modes)
# Applies per-pixel loss weighting based on tumor size using RANO-BM thresholds.
# Smaller tumors receive higher weights to improve reconstruction of clinically
# important small lesions.
#
# Only applies to conditional modes (bravo, dual, multi) where segmentation
# mask is available. Has no effect on unconditional (seg) training.
#
# Weight assignment by Feret diameter (longest edge-to-edge distance):
#   tiny (<10mm): 2.5, small (10-20mm): 1.8, medium (20-30mm): 1.4, large (>=30mm): 1.2
regional_weighting:
  enabled: false              # Enable region-weighted loss
  weights:
    tiny: 2.5                 # <10mm Feret diameter
    small: 1.8                # 10-20mm
    medium: 1.4               # 20-30mm
    large: 1.2                # >=30mm
  background_weight: 1.0      # Weight for non-tumor pixels
  fov_mm: 240.0               # Field of view in mm (for pixel->mm conversion)
