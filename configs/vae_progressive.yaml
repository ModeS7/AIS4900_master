# Progressive VAE Training Configuration
#
# Trains VAE at increasing resolutions (64 -> 128 -> 256) with automatic
# plateau detection for phase transitions. Trains on multiple modalities
# (bravo, flair, t1_pre, t1_gd) to create a pre-trained model.
#
# Usage:
#   # Full progressive training
#   python -m medgen.scripts.train_vae_progressive
#
#   # Resume from checkpoint
#   python -m medgen.scripts.train_vae_progressive \
#       progressive.resume_from=/path/to/progressive_state.pt
#
#   # Custom plateau detection
#   python -m medgen.scripts.train_vae_progressive \
#       progressive.plateau.min_improvement=1.0 \
#       progressive.final_phase.epochs=200
#
# Plateau detection:
#   - Monitors rolling average loss improvement
#   - Transitions to next resolution when improvement < min_improvement%
#   - Patience prevents premature transitions

defaults:
  - paths: local
  - model: default
  - vae: default      # VAE architecture (shared with vae.yaml)
  - training: default
  - _self_

# Progressive training phases
progressive:
  resolutions: [64, 128, 256]  # Resolution progression

  # Batch sizes per resolution (larger batch for smaller images)
  batch_sizes:
    64: 64
    128: 32
    256: 16

  # Plateau detection for phase transition
  plateau:
    window_size: 10          # Rolling window of epochs to consider
    min_improvement: 0.5     # Minimum % improvement required (0.5 = 0.5%)
    min_epochs: 40           # Minimum epochs before checking plateau
    patience: 5              # Epochs below threshold before transition

  # Final phase settings (256x256)
  final_phase:
    epochs: 200              # Fixed epochs at final resolution

  # Resume support
  resume_from: null          # Path to progressive_state.pt to resume

  # Staged training options
  disable_gan: true          # Skip discriminator (faster, more stable)
  use_constant_lr: true      # No LR scheduler, use base learning_rate

# Multi-modality training (each modality as separate 1-channel image)
modalities:
  image_keys: [bravo, flair, t1_pre, t1_gd]  # All modalities mixed (excluding seg)
  in_channels: 1                              # Single channel per image

# Override training defaults
training:
  learning_rate: 1.0e-4
  gradient_clip_norm: 1.0
  warmup_epochs: 3           # Per phase warmup
  # Validates every epoch, figures logged at figure_interval=10
  use_ema: false
  # VAE-specific augmentation (aggressive + batch-level)
  augment_type: vae         # Aggressive augmentation (noise, blur, scale, elastic)
  batch_augment:
    enabled: true           # Enable mixup/cutmix
    mixup_prob: 0.2         # 20% chance per batch
    cutmix_prob: 0.2        # 20% chance per batch
  ema:
    decay: 0.999
    update_after_step: 100
    update_every: 10
  use_multi_gpu: false
  # Logging (all enabled for consistent tracking)
  logging:
    grad_norm: true
    timestep_losses: false    # N/A for VAE
    regional_losses: true     # Tumor/background tracking
    timestep_region_losses: false  # N/A for VAE
    msssim: true
    psnr: true
    lpips: true
    boundary_sharpness: false  # N/A for VAE
    intermediate_steps: false  # N/A for VAE
    worst_batch: true
    num_intermediate_steps: 5
    flops: true

# Hydra configuration
# Output structure: runs/compression_2d/progressive/{name}{timestamp}/
# Use training.name to add experiment prefix: training.name=exp1_ -> exp1_20251215-...
hydra:
  run:
    dir: ${paths.model_dir}/compression_2d/progressive/${oc.select:training.name,""}${now:%Y%m%d-%H%M%S}
  sweep:
    dir: ${paths.model_dir}/compression_2d/progressive/multirun/${now:%Y%m%d-%H%M%S}
    subdir: ${hydra.job.num}
